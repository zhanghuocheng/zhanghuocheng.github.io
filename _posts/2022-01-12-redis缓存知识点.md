---
layout: page
---
[TOC]



![image-20220306100105723](/images/image-20220306100105723.png)

## redis相关

[redis官方教程](http://doc.redisfans.com/ )

### 1 redis基础

##### Redis 过期策略=定期+惰性

```
定期删除+惰性删除
定期：100ms 去随机你检查过期的key
惰性删除：等get key 时检查是否过期
```



##### Redis 内存淘汰机制有以下几个：

```
Redis 内存淘汰机制有以下几个：
- noeviction: 当内存不足以容纳新写入数据时，新写入操作会报错，这个一般没人用吧，实在是太恶心了。
- **allkeys-lru**：当内存不足以容纳新写入数据时，在**键空间**中，移除最近最少使用的 key（这个是**最常用**的）。
- allkeys-random：当内存不足以容纳新写入数据时，在**键空间**中，随机移除某个 key，这个一般没人用吧，为啥要随机，肯定是把最近最少使用的 key 给干掉啊。
- volatile(发了都)-lru：当内存不足以容纳新写入数据时，在**设置了过期时间的键空间**中，移除最近最少使用的 key（这个一般不太合适）。
- volatile-random：当内存不足以容纳新写入数据时，在**设置了过期时间的键空间**中，**随机移除**某个 key。
- volatile-ttl：当内存不足以容纳新写入数据时，在**设置了过期时间的键空间**中，有**更早过期时间**的 key 优先移除
```

##### java LRU

```
public class LRUCache<K, V> extends LinkedHashMap<K, V> {
    private int capacity;

    /**
     * 传递进来最多能缓存多少数据
     *
     * @param capacity 缓存大小
     */
    public LRUCache(int capacity) {
        super(capacity, 0.75f, true);
        this.capacity = capacity;
    }

    /**
     * 如果map中的数据量大于设定的最大容量，返回true，再新加入对象时删除最老的数据
     *
     * @param eldest 最老的数据项
     * @return true则移除最老的数据
     */
    @Override
    protected boolean removeEldestEntry(Map.Entry<K, V> eldest) {
        // 当 map中的数据量大于指定的缓存个数的时候，自动移除最老的数据
        return size() > capacity;
    }
}
```



##### 雪崩-击穿-穿透

```
雪崩-大量缓存过期/redis挂了
击穿-热点数据过期
穿透-数据库和缓存都不存在
```



##### redis和memcache的区别

```
1 redis比memcache支持更多数据结构
2 redis3.x就支持cluster模式，memcache没有原生的集群模式，需要客户端来帮助实现
3 redis是单核，memcache是多核，redis 100k以下 memcache
```

##### redis

1 ansi c语言编写
2 遵守BSD协议的key-value内存数据库
3 支持持久化
4 官网读11w次/S  写 8w次/S
5 处理用户请求还是单线程。处理unlink删除 大key  rdb持久化用后台线程

##### redis数据结构及其原理



Redis的这些数据结构，在底层都是使用redisObject来进行表示。redisObject中有三个重要的属性，分别是type、 encoding 和 ptr。
type表示保存的value的类型。通常有以下几种，也就是常见的五种数据结构：
字符串 REDIS_STRING
列表 REDIS_LIST
集合 REDIS_SET
有序集合 REDIS_ZSET
字典 REDIS_HASH

encoding表示保存的value的编码，通常有以下几种：
#define REDIS_ENCODING_RAW 0            // 编码为字符串
#define REDIS_ENCODING_INT 1            // 编码为整数
#define REDIS_ENCODING_HT 2             // 编码为哈希表
#define REDIS_ENCODING_ZIPMAP 3         // 编码为 zipmap
#define REDIS_ENCODING_LINKEDLIST 4     // 编码为双端链表
#define REDIS_ENCODING_ZIPLIST 5        // 编码为压缩列表
#define REDIS_ENCODING_INTSET 6         // 编码为整数集合
#define REDIS_ENCODING_SKIPLIST 7       // 编码为跳跃表



![image-20220221100543225](/images/image-20220221100543225.png)

redis底层存储 非字符串sds 简单的动态字符串

```
sds 的数据结构
struct sdshdr{
 int len;/*字符串长度*/
 int free;/*未使用的字节长度*/
 char buf[];/*保存字符串的字节数组*/
}

sds和c语言字符串的区别
1 获取字符串的长度 c语言是O(n) sds是O(1)-有记录长度的属性
2 可自动扩展，避免内存溢出
3 空间预分配 根据算法，预先分配适当的free空间
4 惰性释放  不是立即回收多余空间，用free记录多余的空间
5 二进制安全 c语言通过\0标志结束。当我们的字符中有\0就会识别标志出错。sds记录了字符串的长度。故没有这个问题
```

##### redis底层6种数据结构

```
简单动态字符串（SDS）-string
列表- 双向链表，有个长度属性，获取长度的时间复杂度为O1,free属性，实现空间预分配和惰性回收
字典-
整数集合
跳跃表
压缩列表
快速列表
```

##### 字典-

```
二维数组 -链表 实现、
扩容临界值 
		服务器当前没有进行BGWRITEAOF或者BGSAVE命令，且当前键值对个数超过一维数组的大小，才会触发扩容。
		如果当前键值对个数超过一维数组大小的五倍，无论是否在进行BGWRITEAOF或者BGSAVE命令，都会强制扩容。
		如果当前键值对个数少于一维数组大小的十分之一，则触发缩容过程。缩容不会考虑当前服务器是否在进行BGWRITEAOF或者BGSAVE命令。
```





##### redis6特性

```
1 多线程处理io。
2 客户端缓存
3 acl权限控制 分用户，可以给用户分配数据权限
4 RESP3协议 redis 客户端和服务端之间的协议  -目的-->1 为客户端提供更多功能 2 实现客户端缓存  
5 提升RDB 日志加载速度
6 redis集群代理模块 
```

##### redis应用场景

```
高并发 高性能
缓存竞争 缓存与数据库一致性 雪崩 穿透 击穿
```

```
1 高并发替代mysql
2 热点数据缓存
3 消息订阅发布
4 高频读/低频写的数据场景 --排行榜/购物车/字典数据
5 分布式锁
6 快速实现交并差运算
```

##### redis-string基本命令

```
1 get/set  set 如果key存在，即覆盖
2 getset 没有旧值返回nil，有则返回旧值 
3 mget/mset 批量获取/设置 
4 setnx(set if not exists)  存在返回0  失败 ，不存在返回1 成功 
5 incr  会对之前的值+1 eg set key 1 ; INCR KEY ; 此时key的值为2 
```

##### redis-list基本命令

```
1 最多存放2^32 40亿数据
2 rpush 在队尾插入新数据
	lpush 在队首插入新数据
	lrange 获取队列数据
	rpop lpop 从最右侧/左侧弹出数据
```

##### redis-set 无序集合-唯一

##### 扩展功能 lua脚本 pipeline pub/sub geospatial heperLoglog 布隆过滤器 

##### 卡槽设计

##### 单线程模型

```
Redis 内部使用文件事件处理器 file event handler ，这个文件事件处理器是单线程的，所以 Redis 才叫做单线程的模型。它采用 IO 多路复用机制同时监听多个 socket，将产生事件的 socket 压入内存队列中，事件分派器根据 socket 上的事件类型来选择对应的事件处理器进行处理。
文件事件处理器的结构包含 4 个部分：

多个 socket
IO 多路复用程序
文件事件分派器
事件处理器（连接应答处理器、命令请求处理器、命令回复处理器）

多个 socket 可能会并发产生不同的操作，每个操作对应不同的文件事件，但是 IO 多路复用程序会监听多个 socket，会将产生事件的 socket 放入队列中排队，事件分派器每次从队列中取出一个 socket，根据 socket 的事件类型交给对应的事件处理器进行处理。

来看客户端与 Redis 的一次通信过程：
```

![image-20220228094437187](/images/image-20220228094437187.png)



```
要明白，通信是通过 socket 来完成的，不懂的同学可以先去看一看 socket 网络编程。

首先，Redis 服务端进程初始化的时候，会将 server socket 的 AE_READABLE 事件与连接应答处理器关联。

客户端 socket01 向 Redis 进程的 server socket 请求建立连接，此时 server socket 会产生一个 AE_READABLE 事件，IO 多路复用程序监听到 server socket 产生的事件后，将该 socket 压入队列中。文件事件分派器从队列中获取 socket，交给连接应答处理器。连接应答处理器会创建一个能与客户端通信的 socket01，并将该 socket01 的 AE_READABLE 事件与命令请求处理器关联。

假设此时客户端发送了一个 set key value 请求，此时 Redis 中的 socket01 会产生 AE_READABLE 事件，IO 多路复用程序将 socket01 压入队列，此时事件分派器从队列中获取到 socket01 产生的 AE_READABLE 事件，由于前面 socket01 的 AE_READABLE 事件已经与命令请求处理器关联，因此事件分派器将事件交给命令请求处理器来处理。命令请求处理器读取 socket01 的 key value 并在自己内存中完成 key value 的设置。操作完成后，它会将 socket01 的 AE_WRITABLE 事件与命令回复处理器关联。

如果此时客户端准备好接收返回结果了，那么 Redis 中的 socket01 会产生一个 AE_WRITABLE 事件，同样压入队列中，事件分派器找到相关联的命令回复处理器，由命令回复处理器对 socket01 输入本次操作的一个结果，比如 ok ，之后解除 socket01 的 AE_WRITABLE 事件与命令回复处理器的关联。

这样便完成了一次通信。关于 Redis 的一次通信过程，推荐读者阅读《Redis 设计与实现——黄健宏》进行系统学习。

为啥 Redis 单线程模型也能效率这么高？


Redis 6.0 开始引入多线程
注意！ Redis 6.0 之后的版本抛弃了单线程模型这一设计，原本使用单线程运行的 Redis 也开始选择性地使用多线程模型。

前面还在强调 Redis 单线程模型的高效性，现在为什么又要引入多线程？这其实说明 Redis 在有些方面，单线程已经不具有优势了。因为读写网络的 Read/Write 系统调用在 Redis 执行期间占用了大部分 CPU 时间，如果把网络读写做成多线程的方式对性能会有很大提升。

Redis 的多线程部分只是用来处理网络数据的读写和协议解析，执行命令仍然是单线程。 之所以这么设计是不想 Redis 因为多线程而变得复杂，需要去控制 key、lua、事务、LPUSH/LPOP 等等的并发问题。


```

##### Redis 多线程使用

```
Redis 的多线程部分只是用来处理网络数据的读写和协议解析
```

##### 为啥 Redis 单线程模型也能效率这么高？

```
纯内存操作。
核心是基于非阻塞的 IO 多路复用机制。
C 语言实现，一般来说，C 语言实现的程序“距离”操作系统更近，执行速度相对会更快。
单线程反而避免了多线程的频繁上下文切换问题，预防了多线程可能产生的竞争问题。
```



##### 缓存一致性问题

```
1 解决缓存一致性问题 
延迟双删 
1 先删缓存 
2更新数据库 
3根据业务sleep(1)-目的 就是确保读请求结束，写请求可以删除读请求造成的缓存脏数据。 
4 删除缓存
```

问题 后面删除缓存都可能失败 

补偿1  通过业务代码和消息队列做补偿

![image-20220220203338472](/images/image-20220220203338472.png)

补偿2 通过binlog做补偿

![image-20220220203359570](/images/image-20220220203359570.png)

### 2 持久化

```

```

##### Redis 持久化的两种方式

- RDB：RDB 持久化机制，是对 Redis 中的数据执行**周期性**的持久化。
- AOF：AOF 机制对每条写入命令作为日志，以 `append-only` 的模式写入一个日志文件中，在 Redis 重启的时候，可以通过**回放** AOF 日志中的写入指令来重新构建整个数据集。

通过 RDB 或 AOF，都可以将 Redis 内存中的数据给持久化到磁盘上面来，然后可以将这些数据备份到别的地方去，比如说阿里云等云服务。

如果 Redis 挂了，服务器上的内存和磁盘上的数据都丢了，可以从云服务上拷贝回来之前的数据，放到指定的目录中，然后重新启动 Redis，Redis 就会自动根据持久化数据文件中的数据，去恢复内存中的数据，继续对外提供服务。

如果同时使用 RDB 和 AOF 两种持久化机制，那么在 Redis 重启的时候，会使用 **AOF** 来重新构建数据，因为 AOF 中的**数据更加完整**。

##### RDB 优缺点

- RDB 会生成多个数据文件，每个数据文件都代表了某一个时刻中 Redis 的数据，这种多个数据文件的方式，**非常适合做冷备**，可以将这种完整的数据文件发送到一些远程的安全存储上去，比如说 Amazon 的 S3 云服务上去，在国内可以是阿里云的 ODPS 分布式存储上，以预定好的备份策略来定期备份 Redis 中的数据。
- RDB 对 Redis 对外提供的读写服务，影响非常小，可以让 Redis **保持高性能**，因为 Redis 主进程只需要 fork 一个子进程，让子进程执行磁盘 IO 操作来进行 RDB 持久化即可。
- 相对于 AOF 持久化机制来说，直接基于 RDB 数据文件来重启和恢复 Redis 进程，更加快速。
- 如果想要在 Redis 故障时，尽可能少的丢失数据，那么 RDB 没有 AOF 好。一般来说，RDB 数据快照文件，都是每隔 5 分钟，或者更长时间生成一次，这个时候就得接受一旦 Redis 进程宕机，那么会丢失最近 5 分钟（甚至更长时间）的数据。
- RDB 每次在 fork 子进程来执行 RDB 快照数据文件生成的时候，如果数据文件特别大，可能会导致对客户端提供的服务暂停数毫秒，或者甚至数秒。

##### AOF 优缺点

- AOF 可以更好的保护数据不丢失，一般 AOF 会每隔 1 秒，通过一个后台线程执行一次 `fsync` 操作，最多丢失 1 秒钟的数据。
- AOF 日志文件以 `append-only` 模式写入，所以没有任何磁盘寻址的开销，写入性能非常高，而且文件不容易破损，即使文件尾部破损，也很容易修复。
- AOF 日志文件即使过大的时候，出现后台重写操作，也不会影响客户端的读写。因为在 `rewrite` log 的时候，会对其中的指令进行压缩，创建出一份需要恢复数据的最小日志出来。在创建新日志文件的时候，老的日志文件还是照常写入。当新的 merge 后的日志文件 ready 的时候，再交换新老日志文件即可。
- AOF 日志文件的命令通过可读较强的方式进行记录，这个特性非常**适合做灾难性的误删除的紧急恢复**。比如某人不小心用 `flushall` 命令清空了所有数据，只要这个时候后台 `rewrite` 还没有发生，那么就可以立即拷贝 AOF 文件，将最后一条 `flushall` 命令给删了，然后再将该 `AOF` 文件放回去，就可以通过恢复机制，自动恢复所有数据。
- 对于同一份数据来说，AOF 日志文件通常比 RDB 数据快照文件更大。
- AOF 开启后，支持的写 QPS 会比 RDB 支持的写 QPS 低，因为 AOF 一般会配置成每秒 `fsync` 一次日志文件，当然，每秒一次 `fsync` ，性能也还是很高的。（如果实时写入，那么 QPS 会大降，Redis 性能会大大降低）
- 以前 AOF 发生过 bug，就是通过 AOF 记录的日志，进行数据恢复的时候，没有恢复一模一样的数据出来。所以说，类似 AOF 这种较为复杂的基于命令日志 `merge` 回放的方式，比基于 RDB 每次持久化一份完整的数据快照文件的方式，更加脆弱一些，容易有 bug。不过 AOF 就是为了避免 rewrite 过程导致的 bug，因此每次 rewrite 并不是基于旧的指令日志进行 merge 的，而是**基于当时内存中的数据进行指令的重新构建**，这样健壮性会好很多。

##### RDB 和 AOF 到底该如何选择

- 不要仅仅使用 RDB，因为那样会导致你丢失很多数据；
- 也不要仅仅使用 AOF，因为那样有两个问题：第一，你通过 AOF 做冷备，没有 RDB 做冷备来的恢复速度更快；第二，RDB 每次简单粗暴生成数据快照，更加健壮，可以避免 AOF 这种复杂的备份和恢复机制的 bug；
- Redis 支持同时开启开启两种持久化方式，我们可以综合使用 AOF 和 RDB 两种持久化机制，用 AOF 来保证数据不丢失，作为数据恢复的第一选择；用 RDB 来做不同程度的冷备，在 AOF 文件都丢失或损坏不可用的时候，还可以使用 RDB 来进行快速的数据恢复。

RDB-全量二进制备份

```
1 dump.rdb文件 
2 触发rdb四种方式 
	save 阻塞redis其他处理命令
	bgsave fork子进程处理，不会阻塞
	自动化触发通过配置完成 save m n 在m秒内数据集存在n次修改时 自动触发 bgsave
	主从架构，在服务器数据同步时，发送sync ，master主服务器会执行bgsave
	
3 优缺点 
优点 1 rdb文件紧凑 全量备份 2 恢复比aof快 3 rdb文件是紧凑压缩的二进制文件 
缺点：1 全量备份子进程存在开销 2 可能丢失数据

扩展 
文件存放路径 /usr/LOACL/REDIS/DATA
持久化策略 
save 3600 1 
save 300 100 
save 60 10000
导出是否压缩字符串和对象 默认是yes  rdbcompression yes
导入是否检查 
rdbchecksum yes
```

### 3 分布式锁实现 

```
redis 作为分布式锁的相关命令
lock ，`SET key value NX EX seconds`   2.6.12  
unlock del key 解锁是删除key

分布式锁的问题
1 超时问题 --看门狗解决
2 集群同步延迟问题 ---redlock解决

单机redis问题 
1 单机不具备高可用
2 集群场景下，如果A在master拿到了锁,在没有把数据同步到slave时，master挂掉了。B再拿锁就会从slave拿锁，而且会拿到。又出现了两个线程同时拿到锁。
```

##### redlock 原理

用于redis的服务肯定不能是单机，因为单机就不是高可用了，一量挂掉整个分布式锁就没用了。
在集群场景下，如果A在master拿到了锁,在没有把数据同步到slave时，master挂掉了。B再拿锁就会从slave拿锁，而且会拿到。又出现了两个线程同时拿到锁。
基于以上的考虑，Redis 的作者也考虑到这个问题，他提出了一个 RedLock 的算法。
这个算法的意思大概是这样的：假设 Redis 的部署模式是 Redis Cluster，总共有 5 个 Master 节点。
通过以下步骤获取一把锁：

- 获取当前时间戳，单位是毫秒。
- 轮流尝试在每个 Master 节点上创建锁，过期时间设置较短，一般就几十毫秒。
- 尝试在大多数节点上建立一个锁，比如 5 个节点就要求是 3 个节点（n / 2 +1）。
- 客户端计算建立好锁的时间，如果建立锁的时间小于超时时间，就算建立成功了。
- 要是锁建立失败了，那么就依次删除这个锁。
- 只要别人建立了一把分布式锁，你就得不断轮询去尝试获取锁。

但是这样的这种算法还是颇具争议的，可能还会存在不少的问题，无法保证加锁的过程一定正确。
这个问题的根本原因就是redis的集群属于AP，分布式锁属于CP，用AP去实现CP是不可能的。

##### Redisson

```
Redisson通过lua脚本解决了上面的原子性问题，
通过“看门狗”解决了续约问题，
但是它应该解决不了集群中的同步延迟问题。
```

redis集群 setnx 会有哪些问题

redis分布式锁的问题

```
1 客户端长时间阻塞导致锁失效问题
2 redis服务器时钟漂移问题
3 单点实例安全问题
```



### 4 集群部署模式

##### Redis 主从架构

单机的 Redis，能够承载的 QPS 大概就在上万到几万不等。对于缓存来说，一般都是用来支撑**读高并发**的。因此架构做成主从(master-slave)架构，一主多从，主负责写，并且将数据复制到其它的 slave 节点，从节点负责读。所有的**读请求全部走从节点**。这样也可以很轻松实现水平扩容，**支撑读高并发**。

![image-20220228101544722](/images/image-20220228101544722.png)

##### Redis replication 的核心机制

- Redis 采用**异步方式**复制数据到 slave 节点，不过 Redis2.8 开始，slave node 会周期性地确认自己每次复制的数据量；
- 一个 master node 是可以配置多个 slave node 的；
- slave node 也可以连接其他的 slave node；
- slave node 做复制的时候，不会 block master node 的正常工作；
- slave node 在做复制的时候，也不会 block 对自己的查询操作，它会用旧的数据集来提供服务；但是复制完成的时候，需要删除旧数据集，加载新数据集，这个时候就会暂停对外服务了；
- slave node 主要用来进行横向扩容，做读写分离，扩容的 slave node 可以提高读的吞吐量。

注意，如果采用了主从架构，那么建议必须**开启** master node 的[持久化](https://github.com/doocs/advanced-java/blob/main/docs/high-concurrency/redis-persistence.md)，不建议用 slave node 作为 master node 的数据热备，因为那样的话，如果你关掉 master 的持久化，可能在 master 宕机重启的时候数据是空的，然后可能一经过复制， slave node 的数据也丢了。

另外，master 的各种备份方案，也需要做。万一本地的所有文件丢失了，从备份中挑选一份 rdb 去恢复 master，这样才能**确保启动的时候，是有数据的**，即使采用了后续讲解的[高可用机制](https://github.com/doocs/advanced-java/blob/main/docs/high-concurrency/redis-sentinel.md)，slave node 可以自动接管 master node，但也可能 sentinel 还没检测到 master failure，master node 就自动重启了，还是可能导致上面所有的 slave node 数据被清空。

##### Redis 主从复制的核心原理

```
当启动一个 slave node 的时候，它会发送一个 PSYNC 命令给 master node。

如果这是 slave node 初次连接到 master node，那么会触发一次 full resynchronization 全量复制。此时 master 会启动一个后台线程，开始生成一份 RDB 快照文件，同时还会将从客户端 client 新收到的所有写命令缓存在内存中。 RDB 文件生成完毕后， master 会将这个 RDB 发送给 slave，slave 会先写入本地磁盘，然后再从本地磁盘加载到内存中，接着 master 会将内存中缓存的写命令发送到 slave，slave 也会同步这些数据。slave node 如果跟 master node 有网络故障，断开了连接，会自动重连，连接之后 master node 仅会复制给 slave 部分缺少的数据。
```

![image-20220228101800719](/images/image-20220228101800719.png)

##### 主从复制的断点续传

从 Redis2.8 开始，就支持主从复制的断点续传，如果主从复制过程中，网络连接断掉了，那么可以接着上次复制的地方，继续复制下去，而不是从头开始复制一份。

master node 会在内存中维护一个 backlog，master 和 slave 都会保存一个 replica offset 还有一个 master run id，offset 就是保存在 backlog 中的。如果 master 和 slave 网络连接断掉了，slave 会让 master 从上次 replica offset 开始继续复制，如果没有找到对应的 offset，那么就会执行一次 `resynchronization` 。

> 如果根据 host+ip 定位 master node，是不靠谱的，如果 master node 重启或者数据出现了变化，那么 slave node 应该根据不同的 run id 区分。

##### 无磁盘化复制

master 在内存中直接创建 `RDB` ，然后发送给 slave，不会在自己本地落地磁盘了。只需要在配置文件中开启 `repl-diskless-sync yes` 即可。

```
repl-diskless-sync yes

# 等待 5s 后再开始复制，因为要等更多 slave 重新连接过来
repl-diskless-sync-delay 5
```

##### 过期 key 处理

slave 不会过期 key，只会等待 master 过期 key。如果 master 过期了一个 key，或者通过 LRU 淘汰了一个 key，那么会模拟一条 del 命令发送给 slave。

##### 复制的完整流程

slave node 启动时，会在自己本地保存 master node 的信息，包括 master node 的 `host` 和 `ip` ，但是复制流程没开始。

slave node 内部有个定时任务，每秒检查是否有新的 master node 要连接和复制，如果发现，就跟 master node 建立 socket 网络连接。然后 slave node 发送 `ping` 命令给 master node。如果 master 设置了 requirepass，那么 slave node 必须发送 masterauth 的口令过去进行认证。master node **第一次执行全量复制**，将所有数据发给 slave node。而在后续，master node 持续将写命令，异步复制给 slave node。

[![Redis-master-slave-replication-detail](https://github.com/doocs/advanced-java/raw/main/docs/high-concurrency/images/redis-master-slave-replication-detail.png)](https://github.com/doocs/advanced-java/blob/main/docs/high-concurrency/images/redis-master-slave-replication-detail.png)

##### 全量复制

- master 执行 bgsave ，在本地生成一份 rdb 快照文件。
- master node 将 rdb 快照文件发送给 slave node，如果 rdb 复制时间超过 60 秒（repl-timeout），那么 slave node 就会认为复制失败，可以适当调大这个参数(对于千兆网卡的机器，一般每秒传输 100MB，6G 文件，很可能超过 60s)
- master node 在生成 rdb 时，会将所有新的写命令缓存在内存中，在 slave node 保存了 rdb 之后，再将新的写命令复制给 slave node。
- 如果在复制期间，内存缓冲区持续消耗超过 64MB，或者一次性超过 256MB，那么停止复制，复制失败。

```
client-output-buffer-limit slave 256MB 64MB 60
```

- slave node 接收到 rdb 之后，清空自己的旧数据，然后重新加载 rdb 到自己的内存中，同时**基于旧的数据版本**对外提供服务。
- 如果 slave node 开启了 AOF，那么会立即执行 BGREWRITEAOF，重写 AOF。

##### 增量复制

- 如果全量复制过程中，master-slave 网络连接断掉，那么 slave 重新连接 master 时，会触发增量复制。
- master 直接从自己的 backlog 中获取部分丢失的数据，发送给 slave node，默认 backlog 就是 1MB。
- master 就是根据 slave 发送的 psync 中的 offset 来从 backlog 中获取数据的。

##### heartbeat

主从节点互相都会发送 heartbeat 信息。

master 默认每隔 10 秒发送一次 heartbeat，slave node 每隔 1 秒发送一个 heartbeat。

##### 异步复制

master 每次接收到写命令之后，先在内部写入数据，然后异步发送给 slave node。

##### Redis 如何才能做到高可用

如果系统在 365 天内，有 99.99% 的时间，都是可以哗哗对外提供服务的，那么就说系统是高可用的。

一个 slave 挂掉了，是不会影响可用性的，还有其它的 slave 在提供相同数据下的相同的对外的查询服务。

但是，如果 master node 死掉了，会怎么样？没法写数据了，写缓存的时候，全部失效了。slave node 还有什么用呢，没有 master 给它们复制数据了，系统相当于不可用了。

Redis 的高可用架构，叫做 `failover` **故障转移**，也可以叫做主备切换。

master node 在故障时，自动检测，并且将某个 slave node 自动切换为 master node 的过程，叫做主备切换。这个过程，实现了 Redis 的主从架构下的高可用。

后面会详细说明 Redis [基于哨兵的高可用性](https://github.com/doocs/advanced-java/blob/main/docs/high-concurrency/redis-sentinel.md)。

原理

```sequence
从服务器-->主服务器:SYNC请求
主服务器-->主服务器:bgsave创建快照，缓冲快照
主服务器-->从服务器:1 同步快照
从服务器-->从服务器:解析载入快照
主服务器-->从服务器:2 同步写缓冲
从服务器-->从服务器:载入缓冲
主服务器-->从服务器:3 同步增量
```

主从复制优缺点

```
优点
1 主自动同步数据到从，方便读写分离
2 主从同步都为异步，对主服务器和从服务不影响

缺点
1 不具备自动容错和恢复的功能，需要人工介入
2 主机延吉，切换ip后，会有数据不一致问题。
3 slave断线，需用重启，不能同事批量重启，会导致主服务器IO资源紧张
```



##### 哨兵模式

部署图

![image-20220220180257129](/images/image-20220220180257129.png)

哨兵模式

```
哨兵的资料 http://doc.redisfans.com/topic/sentinel.html
客户端连接：通过sentinel client 连接 

redis哨兵的功能 
1 监控 通过ping pong 命令
2 提醒 当发现redis服务异常，通过api向管理员或其他应用程序发送通知
3 故障转移 当主服服务器失效是，让从服务器升级为主服务器，让其他的从服务器复制新的主服务器。给客户端返回新的服务器地址

选举过程  超过半数的sentinel 同意才会执行故障转移

主观下线：一个sentinel认为服务器下线
客观下线：多个sentinel 认为服务器下线，并相互做出交流后，得出服务器下线的判断--只使用主服务器

故障转移的过程

发现主服务器已经进入客观下线状态。
对我们的当前纪元进行自增（详情请参考 Raft leader election ）， 并尝试在这个纪元中当选。
如果当选失败， 那么在设定的故障迁移超时时间的两倍之后， 重新尝试当选。 如果当选成功， 那么执行以下步骤。
选出一个从服务器，并将它升级为主服务器。
向被选中的从服务器发送 SLAVEOF NO ONE 命令，让它转变为主服务器。
通过发布与订阅功能， 将更新后的配置传播给所有其他 Sentinel ， 其他 Sentinel 对它们自己的配置进行更新。
向已下线主服务器的从服务器发送 SLAVEOF 命令， 让它们去复制新的主服务器。
当所有从服务器都已经开始复制新的主服务器时， 领头 Sentinel 终止这次故障迁移操作。

Sentinel 使用以下规则来选择新的主服务器：

在失效主服务器属下的从服务器当中， 那些被标记为主观下线、已断线、或者最后一次回复 PING 命令的时间大于五秒钟的从服务器都会被淘汰。
在失效主服务器属下的从服务器当中， 那些与失效主服务器连接断开的时长超过 down-after 选项指定的时长十倍的从服务器都会被淘汰。
在经历了以上两轮淘汰之后剩下来的从服务器中， 我们选出复制偏移量（replication offset）最大的那个从服务器作为新的主服务器； 如果复制偏移量不可用， 或者从服务器的复制偏移量相同， 那么带有最小运行 ID 的那个从服务器成为新的主服务器。

缺点 难实现动态扩容
```



##### codis 分布式方案

![image-20220220192631718](/images/image-20220220192631718.png)

[codis](https://github.com/CodisLabs/codis)

```

】codis和twemproxy最大的区别有两个：

codis支持动态水平扩展，对client完全透明不影响服务的情况下可以完成增减redis实例的操作；
codis是用go语言写的并支持多线程，twemproxy用C并只用单线程。 后者又意味着：codis在多核机器上的性能会好于twemproxy；codis的最坏响应时间可能会因为GC的STW而变大，不过go1.5发布后会显著降低STW的时间；如果只用一个CPU的话go语言的性能不如C，因此在一些短连接而非长连接的场景中，整个系统的瓶颈可能变成accept新tcp连接的速度，这时codis的性能可能会差于twemproxy。

codis和redis cluster的区别：

redis cluster基于smart client和无中心的设计，client必须按key的哈希将请求直接发送到对应的节点。这意味着：使用官方cluster必须要等对应语言的redis driver对cluster支持的开发和不断成熟；client不能直接像单机一样使用pipeline来提高效率，想同时执行多个请求来提速必须在client端自行实现异步逻辑。 而codis因其有中心节点、基于proxy的设计，对client来说可以像对单机redis一样去操作proxy（除了一些命令不支持），还可以继续使用pipeline并且如果后台redis有多个的话速度会显著快于单redis的pipeline。同时codis使用zookeeper来作为辅助，这意味着单纯对于redis集群来说需要额外的机器搭zk，不过对于很多已经在其他服务上用了zk的公司来说这不是问题：）

Codis 由四部分组成:
Codis Proxy (codis-proxy)，处理客户端请求，支持Redis协议，因此客户端访问Codis Proxy跟访问原生Redis没有什么区别；
Codis Dashboard (codis-config)，Codis 的管理工具，支持添加/删除 Redis 节点、添加/删除 Proxy 节点，发起数据迁移等操作。codis-config 本身还自带了一个 http server，会启动一个 dashboard，用户可以直接在浏览器上观察 Codis 集群的运行状态；
Codis Redis (codis-server)，Codis 项目维护的一个 Redis 分支，基于 2.8.21 开发，加入了 slot 的支持和原子的数据迁移指令；
ZooKeeper/Etcd，Codis 依赖 ZooKeeper 来存放数据路由表和 codis-proxy 节点的元信息，codis-config 发起的命令都会通过 ZooKeeper 同步到各个存活的 codis-proxy；

Codis 采用 Pre-sharding 的技术来实现数据的分片，默认分成 1024 个 slots (0-1023)，对于每个key来说，通过以下公式确定所属的 Slot Id：

SlotId = crc32(key) % 1024
每一个 slot 都会有一个且必须有一个特定的 server group id 来表示这个 slot 的数据由哪个 server group 来提供。数据的迁移也是以slot为单位的。
```

##### Cluster 集群模式（Redis官方）

![image-20220220184110716](/images/image-20220220184110716.png)

集群模式

```
集群特点:任何节点都是相互联通的
redis集群的分片：没有使用一致性hash 引入hash slot 16384  通过key crc16校验后 对16384 取模 来决定哪个槽
cluster;管理集群的插件，通过key算出槽，判断在个节点上

```

##### redis同城双活

```

```

#### 5 大key

##### 大key 大小和数量上

```
单key大小
Redis限制每个String类型value大小不超过512MB， 实际开发中，不要超过10KB，
否则会对CPU和网卡造成极大负载。 hash、list、set、zset元素个数不要超过5000。
理论上限: 每个hashset里头元素数量< 2^32. key的数量 官方评测： 单实例2.5亿 理论上限: 32位，2^32。约40亿
怎么检测 1 bigkeys 2 用脚本迭代 scan key  3 通过dump rdb文件分析大key 
怎么解决：Redis 4.0及之后版本：您可以通过UNLINK命令安全地删除大Key甚至特大Key，该命令能够以非阻塞的方式，逐步地清理传入的Key。 Redis 4.0之前的版本：建议先通过SCAN命令读取部分数据，然后进行删除，避免一次性删除大量key导致Redis阻塞。

危害;内存空间不均匀，操作耗时，网络阻塞

```

##### 集群原理

##### Redis cluster 介绍

- 自动将数据进行分片，每个 master 上放一部分数据
- 提供内置的高可用支持，部分 master 不可用时，还是可以继续工作的

在 Redis cluster 架构下，每个 Redis 要放开两个端口号，比如一个是 6379，另外一个就是 加 1w 的端口号，比如 16379。

16379 端口号是用来进行节点间通信的，也就是 cluster bus 的东西，cluster bus 的通信，用来进行故障检测、配置更新、故障转移授权。cluster bus 用了另外一种二进制的协议， `gossip` 协议，用于节点间进行高效的数据交换，占用更少的网络带宽和处理时间。

##### 节点间的内部通信机制

##### 基本通信原理

集群元数据的维护有两种方式：集中式、Gossip 协议。Redis cluster 节点间采用 gossip 协议进行通信。

**集中式**是将集群元数据（节点信息、故障等等）集中存储在某个节点上。集中式元数据集中存储的一个典型代表，就是大数据领域的 `storm` 。它是分布式的大数据实时计算引擎，是集中式的元数据存储的结构，底层基于 zookeeper（分布式协调的中间件）对所有元数据进行存储维护。

![image-20220228102629375](/images/image-20220228102629375.png)



```
Redis 维护集群元数据采用另一个方式， gossip 协议，所有节点都持有一份元数据，不同的节点如果出现了元数据的变更，就不断将元数据发送给其它的节点，让其它节点也进行元数据的变更。
```





##### 一致性算法


